{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Tensor的存储\n",
    "### 2.4.1 Storage\n",
    "tensor中的值是存储在连续的内存块中的，由torch.Storage实例管理着。一个storage即是一个一维的向量。\n",
    "\n",
    "多个不同的tensor可以存储在同一个storage中，只是对数据的索引不同，入下图，一个2行3列的tensor和3行2列的tensor的值都存储在同一个storage中，其中storage中索引为0位置存储着两个tensor的第一行第一列的值4。正因如此，当从一个已有的Tensor创建一个新的tensor时总能很快，因为其在内存中只会创建一次。\n",
    "![jupyter](./image/4.png)\n",
    "\n",
    "现在来看看可以用哪些api来操作storage：\n",
    "\n",
    "**获取tensor的storage:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0\n",
       " 4.0\n",
       " 2.0\n",
       " 1.0\n",
       " 3.0\n",
       " 5.0\n",
       "[torch.FloatStorage of size 6]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# 3*2的tensor\n",
    "points = torch.tensor([[1.0, 4.0],[2.0, 1.0],[3.0, 5.0]])\n",
    "points.storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**对storage进行索引：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_storage = points.storage()\n",
    "points_storage[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：storage永远是一维的数组，任何维度的tensor都存储在一维的storage中。\n",
    "\n",
    "**更改storage的值：**\n",
    "\n",
    "tensor的值存储在storage中，若改变了storage的值，势必会改变tensor的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 4.],\n",
      "        [2., 1.],\n",
      "        [3., 5.]])\n"
     ]
    }
   ],
   "source": [
    "points_storage = points.storage()\n",
    "points_storage[0] = 2.0\n",
    "print(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可见，改变了points的storage中索引为0的值，同时也改变了points中第一行第一列的值。\n",
    "\n",
    "现在，你知道了tensor的值时存储在storage中，但你肯定会疑惑，我们如何知道在tensor中的某个值，存储在storage的什么位置，也就是说如何知道storage时如何存储tensor的。Pytorch中提供了3个信息来连接tensor与storage: size, storage offset, strides。下面三小节会依次介绍它们。\n",
    "\n",
    "### 2.4.2 size\n",
    "size（在numpy中叫shape) 是一个元组，显示tensor中每个维度的元素数量。这个大家自然是不陌生，如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "points = torch.tensor([[1.0, 4.0],[2.0, 1.0],[3.0, 5.0]])\n",
    "print(points.size())  # 打印size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 storage offset\n",
    "storage offset是指tensor的第一个元素在storage中的位置，再来看之前的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0\n",
       " 4.0\n",
       " 2.0\n",
       " 1.0\n",
       " 3.0\n",
       " 5.0\n",
       "[torch.FloatStorage of size 6]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3*2的tensor\n",
    "points = torch.tensor([[1.0, 4.0],[2.0, 1.0],[3.0, 5.0]])\n",
    "points.storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们取出points中的一维，生成一个新的tensor, 注意新的tensor与points仍然是同一个storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "points_second = points[1]\n",
    "print(points_second.storage_offset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "points_second应为：tensor([2., 1.]), 它的第一个元素在storage中位置为索引为2的地方。\n",
    "\n",
    "### 2.4.4 stride\n",
    "首先明确strides是一个N元组。它表示步长，即Tensor中的某个元素，需要在storage中跳过多少数量的元素才能到达tensor中每个维度中的下一个元素。说起来太拗口，来看下面这个例子吧：\n",
    "\n",
    "左边是一个tensor， 3行3列，size=(3,3)， 总共由两个维度，每个维度中的元素数目都是3个；\n",
    "下面的蓝色一维数组是它的storage；\n",
    "该tensor的第一个元素5在storage中的索引是1，因此offset=1;\n",
    "先在来看strides, 以tensor中的其中一个元素（第一行第一列的5）为例，它的索引维（0，0），在第1维中，它的下一个元素（0，1）为1，在storage中就存在5的后面一个位置，因此它在第1维中到达下一个元素的步长为1；在第0维中，5的下一个元素（1，0）是1，在storage中存储在离5有3个步长的地方；因此该tensor的strides为（1，3）\n",
    "![jupyter](./image/5.png)\n",
    "将上述例子用代码表示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.Tensor([[5,7,4],[1,3,2],[7,3,8]])\n",
    "points.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "综上所述，可以根据offset和stride来从storage的元素中获取tensor中的元素，其公式如下：\n",
    "storage_offset + stride[0] * i + stride[1] * j\n",
    "\n",
    "### 2.4.5 获取子tensor\n",
    "因为tensor和storage的关系，使得一些操作变得轻而易举，因为不需要再重新分配内存。像这样的操作典型的如“获取子tensor”和“转置Tensor”，分别在这节和下一节来详细讲一讲，并看看stride, offset等的变化。\n",
    "\n",
    "如下例子， 创建一个tensor名为points, 再以该points创建出其的子tensor，此时，这两个tensor是同一个storage, 只是stride, offset, size不同, 请品味："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "(2, 1)\n",
      "0\n",
      "torch.Size([2])\n",
      "(1,)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# 创建一个3*2的tensor\n",
    "points = torch.tensor([[1.0, 4.0],[2.0, 1.0],[3.0, 5.0]])\n",
    "print(points.size())  # (3,2)\n",
    "print(points.stride())  # (1,2)\n",
    "print(points.storage_offset())  # 0\n",
    "\n",
    "# 创建Points的子tensor\n",
    "points_second = points[1]\n",
    "print(points_second.size())  # 2\n",
    "print(points_second.stride()) # (1,)\n",
    "print(points_second.storage_offset())  # 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若更改子tensor的值，则原tensor的值也会随之改变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  4.],\n",
      "        [10.,  1.],\n",
      "        [ 3.,  5.]])\n"
     ]
    }
   ],
   "source": [
    "# 更改子tensor的值\n",
    "points_second[0] = 10.0\n",
    "print(points) # 原tensor的值也会随之改变"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但现实中，我们往往不希望原tensor跟着子tensor变动，此时可以使用.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "second_points = points[1].clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.6 转置tensor\n",
    "转置前后的Tensor元素的值没有变化，只是变化了元素的位置，因此其stride, offset, size也随之而变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "(2, 1)\n",
      "0\n",
      "torch.Size([2, 3])\n",
      "(1, 2)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 创建一个3*2的tensor\n",
    "points = torch.tensor([[1.0, 4.0],[2.0, 1.0],[3.0, 5.0]])\n",
    "print(points.size())  # (3,2)\n",
    "print(points.stride())  # (1,2)\n",
    "print(points.storage_offset())  # 0\n",
    "\n",
    "# 创建Points的子tensor\n",
    "points_t = points.t()\n",
    "\n",
    "id(points.storage()) == id(points_t.storage())  # True, 转置后storage同一个\n",
    "\n",
    "print(points_t.size())  # (2,3)\n",
    "print(points_t.stride()) # (2,1)\n",
    "print(points_t.storage_offset())  # 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下图可帮助理解：\n",
    "![jupyter](./image/6.png)\n",
    "\n",
    "上面是对于二维矩阵的转置操作，对于多维数组，同样也是这个例，请看以下例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n",
      "(20, 5, 1)\n",
      "torch.Size([5, 4, 3])\n",
      "(1, 5, 20)\n"
     ]
    }
   ],
   "source": [
    "some_tensor = torch.ones(3,4,5) # 创建3*4*5的tensor\n",
    "print(some_tensor.size()) # (3,4,5)\n",
    "print(some_tensor.stride()) # (20, 5, 1)\n",
    "\n",
    "some_tensor_t = some_tensor.transpose(0,2) # 将第0维于第2维互换\n",
    "print(some_tensor_t.size()) # (5,4,3)\n",
    "print(some_tensor_t.stride()) # (1, 5, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.7 连续型Tensor\n",
    "如果一个Tensor在storage中的存储顺序是从左倒右地存储它的元素，比如二位矩阵，是从左到右从上到下一行一行存储的，就称该Tensor为contiguous tensor。contiguous tensor使得有序高效访问元素，而无需根据太大的步长进行跳跃获取。\n",
    "\n",
    "这么说，如果对一个tensor进行转置后，那么对于转置后的tensor就不是contiguous tensor了， 可以通过.is_contiguous()来判断。\n",
    "\n",
    "如果想要tensor变得contiguous, 可以使用.contiguous()来创建一个新的内容没有改变的contiguous tensor："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "(2, 1)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 创建一个3*2的tensor\n",
    "points = torch.tensor([[1.0, 4.0],[2.0, 1.0],[3.0, 5.0]])\n",
    "print(points.size())  # (3,2)\n",
    "print(points.stride())  # (1,2)\n",
    "print(points.storage_offset())  # 0\n",
    "\n",
    "# 创建Points的子tensor\n",
    "points_t_c = points.t().contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.8 总结\n",
    "本章讲了tensor的存储，处了本节的总结，总共有7个小节，可以分成3部分去学习：\n",
    "第1节--讲了tensor是存储在storage中的\n",
    "第2、3、4节--讲述了tensor和storage之间的联系，分别是通过3个信息size, stride, offset来对接两者的关系\n",
    "第5、6、7节--讲述了由于tensor和storage这个的关系而让一些操作变得简单，如获取子tensor, 转置tensor, 并叙述可以通过.contiguous()来创建连续tensor。\n",
    "\n",
    "这一节的内容在实际工作中不会太多用到，但掌握tensor的存储可以有助于大家理解tensor的运作原理，并更好地撰写高效的代码。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
